// SPDX-License-Identifier: GPL-3.0-or-later

package com.sciencesakura.gjsonp

import spock.lang.Specification

class LexerSpec extends Specification {

  def 'ignore whitespace characters and control characters'() {
    given:
    def text = ' \t\n\r\u0000'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens.empty
  }

  def 'recognize symbols'() {
    given:
    def text = '.[]'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.Period(1),
        new Token.LeftBracket(2),
        new Token.RightBracket(3),
    ]
  }

  def 'recognize integers'() {
    given:
    def text = '1 234'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.Integer(1, 1),
        new Token.Integer(3, 234),
    ]
  }

  def 'recognize strings'() {
    given:
    def text = 'Hello OlÃ¡ ã“ã‚“ã«ã¡ã¯ ä½ å¥½ ì•ˆë…•í•˜ì„¸ìš” ğŸ‘‹ğŸ‘‹ğŸ»ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ½ğŸ‘‹ğŸ¾ğŸ‘‹ğŸ¿'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.String(1, 'Hello'),
        new Token.String(7, 'OlÃ¡'),
        new Token.String(11, 'ã“ã‚“ã«ã¡ã¯'),
        new Token.String(17, 'ä½ å¥½'),
        new Token.String(20, 'ì•ˆë…•í•˜ì„¸ìš”'),
        new Token.String(26, 'ğŸ‘‹ğŸ‘‹ğŸ»ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ½ğŸ‘‹ğŸ¾ğŸ‘‹ğŸ¿'),
    ]
  }

  def 'ignore control characters in strings'() {
    given:
    def text = 'a\u0000b\u0001c\u0002'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.String(1, 'abc'),
    ]
  }

  def 'recognize quoted strings'() {
    given:
    def text = '"foo bar" "\\b\\f\\n\\r\\t\\\\"'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.String(1, 'foo bar'),
        new Token.String(11, '\b\f\n\r\t\\'),
    ]
  }

  def 'ignore control characters in quoted strings'() {
    given:
    def text = '"a\u0000b\u0001c\u0002"'

    when:
    def tokens = new Lexer(text).toList()

    then:
    assert tokens == [
        new Token.String(1, 'abc'),
    ]
  }

  def "throw exception for unterminated string: '\"foo'"() {
    given:
    def text = '"foo'

    when:
    new Lexer(text).toList()

    then:
    def e = thrown(InvalidExpressionException)
    assert e.message == 'Unterminated string at 4'
  }

  def "throw exception for unterminated string: '\"'"() {
    given:
    def text = '"'

    when:
    new Lexer(text).toList()

    then:
    def e = thrown(InvalidExpressionException)
    assert e.message == 'Unterminated string at 1'
  }
}
